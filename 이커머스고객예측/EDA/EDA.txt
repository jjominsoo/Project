# 확인
RFM 분석 :  얼마나 최근에(R), 얼마나 자주(F), 얼마나 많이(M) 구매 활동을 했는가에 대한 정보를 만들고 
이를 바탕으로 고객의 상태를 세분화하는 모델
마케팅 메시지를 세그먼트에 맞춰 여러 플랫폼에서 다르게 전달하여 전환을 유도해야 합니다

4. 시간대 별 소비패턴 (초중말, 년, 월, 평일주말, 가입기간)
2. 배송료별 소비패턴
3. 온/오프라인 별 소비패턴

일단 기본적인 RFM을 통해 그룹별로 나누고
그 군집별로 RFM을 실시하는 것이 좋아보임

1. 성별 
2. 제품카테고리, 쿠폰코드(할인율), 가입기간(CLV) + RFM  배송료
3. 고객지역
4. 거래날짜(초중말,년,월,요일) 
5. 온/오프라인비용

==========================================================================================
배경
https://www.adjust.com/ko/blog/customer-segmentation-explained/
1.인구학적 세분화: 		성별, 연령, 직업, 소득, 교육 수준1, 가족 관계 등에 따른 세분화
2.심리학적 세분화: 		라이프스타일, 태도, 가치, 관심사, 성격적 특징, 취미 등에 따른 세분화.
3.지리학적 세분화: 		우편번호, 도시, 지역, 주, 국가에 따른 세분화.
4.행동학적 세분화: 		구매 습관, 앱 기능 사용 패턴, 세션 빈도수, 검색 기록, 평균 구매액, 구매 내역 등에 따른 세분화.
5.기술적 세분화: 		고객의 모바일 기기나 소프트웨어에 따른 세분화.

*가장 가치 있는 사용자가 누구인지 정의하기.
예를 들어, 앱에서 가장 많은 시간을 보내는 사용자, 앱을 자주 여는 사용자, 앱에서 가장 많은 인앱 구매를 하는 사용자 중 
어느 사용자가 가장 가치 있는 사용자인지 결정해야 합니다. 
비즈니스의 전반적인 전략에 따라 가치 있는 사용자의 카테고리가 여러 개 존재할 수도 있습니다. 
이러한 경우에는, 카테고리별로 아래 과정을 거쳐 타겟화된 마케팅에 적절한 규모의 세그먼트가 무엇인지 파악해야 합니다.

*어느 채널에서 가장 가치 있는 사용자가 유입되었는지 분석하기.
가장 UA 성과가 높은 채널이 실제로 가장 가치 높은 사용자의 유입에 기여하는 채널일 수도 있지만, 
사용자 유입 규모와 유입된 사용자의 가치는 항상 비례하지 않기 때문에 
예상치 못한 채널에서 가장 가치가 높은 사용자를 많이 유치할 수도 있습니다.

*사용자간 공통점 파악하기.
고객 세분화의 주요 유형을 분석하여, 일관적인 공통점이 있는지 파악해야 합니다. 
예를 들어, 가장 앱에서 구매를 많이 하는 사용자들이 만 37~43세 남성 또는 만 29세~35세 여성들인데, 
두 그룹 모두 미국 동부에 거주한다는 것을 발견할 수 있습니다. 이러한 정보를 최대한 많이 수집할수록 효과적입니다.

*사용자가 앱을 어떻게 사용하는지 분석하기.
사용자들이 특정 요일이나 시간에 더욱 활동적인가요? 
사용자의 평균 세션 빈도수와 평균 세션 길이, 앱에서 가장 많이 사용하는 기능이 무엇인지 파악하시기 바랍니다.

*수집한 데이터에서 인사이트 뽑아내기.
위 단계에서 얻은 정보를 분석하여, 특정 소비자 세그먼트의 관심사, 행동, 라이프 스테이지나 니즈를 알아낼 수 있습니다.

*주력해야 할 세그먼트 선정 및 평가하기.
이 단계는 여러 세그먼트로부터 충분한 소비자 트렌드와 패턴 파악을 완료한 이후의 단계입니다. 
모든 세그먼트가 맞춤형 캠페인에 적합한 것은 아니므로 집중 세그먼트(규모는 작으나 가치가 매우 높은 사용자들)에 대해 
고도의 맞춤화를 통해 소비자와 더욱 깊은 관계를 구축해야 합니다.

======================
CLV ARPPU retention 장바구니분석 rfm



=================================================================================
데이터
dfC	: 고객ID, 성별, 고객지역, 가입기간
dfD	: 월, 제품카테고리, 쿠폰코드, 할인율
dfM	: 날짜, 오프라인비용, 온라인비용
dfO	: 고객ID, 거래ID, 거래날짜, 제품ID, 제품카테고리, 수량, 평균금액, 배송료, 쿠폰상태
dfT	: 제품카테고리, GST






예제
1. 트리플송
1-1. LRFMV모델 > 이익극대화 측면의 고객 분석
각 고객ID마다 어떤 상품을 샀는지 sum값을 보여줌 ( df_pv )
L : 고객 마지막 거래날짜 - 고객 처음 거래날짜
R : 기준날짜 - 고객 마지막 거래날짜
F : 고객 거래ID 의 count값
M: 고객 구매금액의 sum값 
V : 고객 하루동안 구매한 상품의 mean값

1-2. 쿠폰민감도


1-2. K-mediods > 이상치의 영향을 덜받는 군집 도출
+고객충성도/유지비용에 따른 군집( 로열고객 고성과고객 범용고객 저성과고객 )














2. ACTIVE
RFM > 활성화 고객층의 멤버십제도, 상위등급 업그레이드 전략
+R=4 / F에 따른 멤버십 / 
연관분석 > 


===============================================
1. 시간대 별 소비패턴 (초중말, 년, 월, 평일주말, 가입기간)
2. 배송료별 소비패턴
3. 온/오프라인 별 소비패턴

===================================================
멘토미팅 리뷰

어떤 메소드들을 학습함에 있어서는 이해를 하는 것이다.
좋은 코드 참고하는 것도 좋지만
'왜' 이 부분에서 이 알고리즘을 사용했는 지를 이해하고 
데이터 특성을 봤을 때 어떤 분석을 했어야 해서 어떤 알고리즘을 리서치했고
각 알고리즘의 장단점을 파악하고 활용해 해당 프로젝트에서 어떤 알고리즘을 사용했는지에 대한 설명이 필요 

알고리즘/분석방법에 대한 이해
왜 군집화에 K-Mediods사용? 
RFM분석에 대한 이해

유클리드/맨해튼 > 를 통해 K-Means를 사용할때
1.구형의 클러스터 (장단점[응집도])  / 2.






=========================================================
1. 데이터 분석
> RFM분석을 할 때 어떤 부분에 가중치를 둘지 결정
R(최근) F(자주) M(얼마)
( 만약 모든 고객이 구매하는 금액이 비슷하면 M에 가중치를 적게
모든 고객이 비슷한 시기에 구매한다면 R에 가중치를 적게
모든 고객이 비슷한 주기로 구매한다면 F에 가중치를 적게




======================================================================================
0	127	중	크	크	잠재VIP
1	368	적	적	적	자주방문하는데 별로 안사는 사람들	탐색고객 (구매결정 못함, 비교분석을함, 브랜드이해/관심 높음 > 유용한정보나 맞춤프로모션 제공)
2	285	크	적	적	이탈고객
3	468	중	적	적	일반고객
4	220	적	크	크	프리미엄
===============================
전체		145	36	2964

0		168	88	6943
1		46	18	1633
2		303	20	1683
3		167	17	1069
4		43	94	8583











생각보다 이탈 위험 고객이 많음
> 줄일까? 그럼 Recent에서 좀 손봐야할듯

+사용자 중에 주기적인(여름에만 구매) 구매를 하는 사람은 분류를 어떻게 해야하나








고객데이터 전처리
Raw데이터는 데이터 편향성도 짙고(Long tail) 원하는 고객세분화가 나올것 같지 않아서 전처리를 하기로 함 

1. RFM Score
R 칼럼은 비교적 원하는 방향성을 갖고 있으므로 단순히 qcut을 통해서 %별로 나눔
따라서 F, M 칼럼에 대해서 기준을 가지고 섹션을 나누기로 함
일단 데이터셋을 outlier를 기준으로 나눔 ( 이상치 이전의 데이터셋 A / 이상치 이후의 데이터셋 B )
1-1. 4 Section
  min~A.mean()  / ~outlier / ~B.mean() / ~max
1-2. 5 Section
  이상치 이후 데이터들(B)에서도 이상치가 있을 것이니 그것을 기준으로 또 나눠봄 ( C )
  min~A.mean() / ~outlier / ~B.mean() / ~C / ~max
2. Robust Scaling
  이상치가 많고 이상치에 민감하므로 중앙값과 IQR을 사용해 이상치 영향을 줄일 수 있다.
3. Log Scaling
  데이터가 급격하게 변하는 양상이므로 적합하다 .. 정규분포에 가깝게


Cluster 후보
Loss 최소값 모델 선택 (K-means)	Elbow에서 최적의 K값 찾고 실루엣함수로 평가
	Loss			Elbow		Silhouettte
1-1. 	779 / 607 .. 686		4 / 779		0.5237 0.5390
1-2. 	1182 / 913 .. 997		4 / 1063		0.4325 0.4796
2.	1477 / 1173 .. 1476	4 / 1477.731	0.4621 0.3584
3.	1961 / 1579 .. 1794	4 / 1961.867	0.3710 0.3577

>> 1-1 4Section으로 나눈걸 채택

	갯수	R	F	M	해석							등급
0	195	크	크	크	높은 방문율과 구매율을 가졌지만 방문이 뜸해진 고객		재구매 유도 고객
1	390	적	적	적	자주 방문하지만 높은 실적을 남기진 않는 금액			일반 고객
2	351	적	크	크	최근까지도 방문하며 매장에 이익을 가져다 주는 우수 고객		프리미엄
3	532	크	적	적	방문도 뜸하고 구매율이 적은 고객들				이탈위험고객
===============================
전체		145	36	2964

0		229	62	4822
1		63	14	1149
2		57	80	7154
3		232	12	849

62 768 252 386

전 145 36 2964
0 44 192 17659
1 188 13 900
2 21 30 2805
3 155 60 4814
============================================
소현님 EDA 

F, M 구간
0~25 / 25~50 / 50~outlier / outlier~max

		R	F	M
로열고객		<2	>3	>3	
고성과고객	>3	<2	>3
저성과고객	>3	<2	<2
일반고객		그외	그외	그외


RFM Score값을 정하고
나) K means 클러스터링을 진행
소현) 기준을 또 생각해서 미리 클러스터링 진행





질문 1.
비율은 적절한가?
일반고객이 많아야하는데 난 너무 골고루 나온거 같긴함
이탈위험고객이 많다. > R 기준 다시 세워봐
질문 2.
K-means 는 분산이 유사하면 효율적으로 나온다는데 
분산이 비슷한 log처리 데이터는 손실함수가 큼 
그럼 이럴땐 모델 효율을 줄이더라도 내가한 rfmscore을 가야하느냐 아님 모델의 성능을 우선시하는 게 좋겟냐
물론 목적에 맞는 



2226 4583 5700





0 683                 : 일반고객
1 1358              : 재구매유도 고객
2 190               : 프리미엄 고객
3 1277              : 이탈위험 고객

